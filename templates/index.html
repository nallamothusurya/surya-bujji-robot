<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <title>Bujji - Your AI Companion</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/recorderjs/0.1.0/recorder.min.js"></script>
  <style>
    .container {
      max-width: 600px;
      margin: 0 auto;
      padding: 10px;
    }
    html, body {
      margin: 0;
      padding: 0;
      min-height: 100vh;
      display: flex; /* For centering content */
      flex-direction: column; /* For centering content */
      align-items: center; /* For centering content */
      justify-content: center; /* For centering content */
    }
    body {
      background: linear-gradient(-45deg, #2d2d2d, rgb(255, 0, 0), #0bf, #000);
      background-repeat: no-repeat;
      background-size: cover;
      transition: background 0.5s ease;
      -webkit-transition: background 0.5s ease;
    }
    body.speaking-active { /* Changed class name for clarity */
      background: linear-gradient(-45deg, #e16100, #b500e2, #00acd3, #23d5ab);
      background-size: 400% 400%;
      animation: gradientShift 8s ease infinite;
      -webkit-animation: gradientShift 8s ease infinite;
    }
    @-webkit-keyframes gradientShift {
      0%   { background-position: 0% 50%; }
      50%  { background-position: 100% 50%; }
      100% { background-position: 0% 50%; }
    }
    @keyframes gradientShift {
      0%   { background-position: 0% 50%; }
      50%  { background-position: 100% 50%; }
      100% { background-position: 0% 50%; }
    }
    h1 {
      text-align: center;
      color: #fff;
      margin-bottom: 20px;
    }
    #languageSelect,
    #microphoneBtn {
      display: block;
      margin: 10px auto;
    }
    #languageSelect {
      padding: 5px 10px;
      font-size: 1rem;
      border-radius: 5px;
      border: 1px solid #ccc;
    }
    #microphoneBtn {
      width: 60px;
      height: 60px;
      border-radius: 50%;
      background-color: #eee;
      border: none;
      cursor: pointer;
      position: relative;
      transition: background-color 0.3s ease, box-shadow 0.3s ease;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
    }
    #microphoneBtn:hover {
      background-color: #ddd;
    }
    #microphoneBtn::before {
      content: "\f130"; /* Microphone icon */
      font-family: "Font Awesome 5 Free";
      font-weight: 900;
      font-size: 1.5rem;
      color: #555;
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
    }
    #microphoneBtn.active {
      background-color: #dc3545;
      box-shadow: 0 0 15px rgba(220,53,69,0.6);
    }
    #microphoneBtn.active::before {
      color: #fff;
    }
    #microphoneBtn.active::after {
      content: '';
      position: absolute;
      width: 120%;
      height: 120%;
      top: -10%;
      left: -10%;
      background-color: rgba(220, 53, 69, 0.3);
      border-radius: 50%;
      animation: pulse 1.5s infinite;
      z-index: -1;
    }
    @-webkit-keyframes pulse {
      0% { transform: scale(1); opacity: 0.5; }
      100% { transform: scale(1.3); opacity: 0; }
    }
    @keyframes pulse {
      0% { transform: scale(1); opacity: 0.5; }
      100% { transform: scale(1.3); opacity: 0; }
    }
    #textFallback {
      display: none;
      text-align: center;
      margin: 20px auto;
    }
    #textInput {
      padding: 10px;
      width: 70%;
      font-size: 1rem;
      border: 1px solid #ccc;
      border-radius: 5px;
    }
    #sendTextBtn {
      padding: 10px 15px;
      font-size: 1rem;
      margin-left: 5px;
      border: none;
      border-radius: 5px;
      background-color: #0f1a1e;
      color: #fff;
      cursor: pointer;
      transition: background-color 0.3s ease;
    }
    #sendTextBtn:hover {
      background-color: #333;
    }
    
    /* Avatar Video Styling */
    #avatarVideoContainer {
        display: flex;
        justify-content: center;
        align-items: center;
        margin: 20px auto;
        width: 300px; /* Desired width */
        height: 300px; /* Desired height */
        border: 3px solid #0f1a1e;
        border-radius: 50%; /* Make it circular */
        box-shadow: 0 0 10px rgba(15,26,30,0.3);
        overflow: hidden; /* Important for circular mask */
        background-color: #1a1a1a; /* Fallback background */
    }
    #avatarVideo {
        width: 100%;
        height: 100%;
        object-fit: cover; /* Cover the area, may crop */
    }
    body.speaking-active #avatarVideoContainer {
      border-color: #dc3545;
      animation: pulseBorder 1.5s infinite;
    }
     @-webkit-keyframes pulseBorder {
      0% { box-shadow: 0 0 5px rgba(220,53,69,0.5); }
      50% { box-shadow: 0 0 20px rgba(220,53,69,1); }
      100% { box-shadow: 0 0 5px rgba(220,53,69,0.5); }
    }
    @keyframes pulseBorder {
      0% { box-shadow: 0 0 5px rgba(220,53,69,0.5); }
      50% { box-shadow: 0 0 20px rgba(220,53,69,1); }
      100% { box-shadow: 0 0 5px rgba(220,53,69,0.5); }
    }

    /* Hidden camera and canvas for frame capture */
    #cameraFeed, #captureCanvas {
        display: none;
    }

    #conversation {
      margin-top: 20px;
      padding: 15px;
      background: #fff;
      border-radius: 10px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.1);
      max-height: 200px; /* Adjusted */
      overflow-y: auto;
      font-size: 0.95rem;
      width: 100%; /* Ensure it takes container width */
    }
    #conversation p {
      margin: 5px 0;
      line-height: 1.4;
    }
    audio {
      margin: 10px auto;
      display: block;
      width: 100%;
      max-width: 300px;
    }
    @media (max-width: 768px) {
      h1 { font-size: 1.5rem; }
      #microphoneBtn { width: 50px; height: 50px; }
      #microphoneBtn::before { font-size: 1.25rem; }
      #conversation { max-height: 150px; padding: 10px; }
      #textInput { width: 60%; }
      #avatarVideoContainer { width: 200px; height: 200px; }
    }
    .author {
      text-align: center;
      color: #fff;
      font-size: 0.8rem;
      font-weight: bold;
      margin-top: 10px; /* Adjusted */
      font-style: italic;
      opacity: 0.8;
    }
    .author a {
      color: rgb(0, 253, 21);
      transition: color 0.3s ease;
      text-decoration:none;
      font-weight:bolder;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>Bujji - Your AI Companion</h1>
    <select id="languageSelect"></select>
    
    <!-- Avatar Video Display -->
    <div id="avatarVideoContainer">
      <video id="avatarVideo" loop muted playsinline autoplay></video>
    </div>
    
    <!-- Hidden elements for camera capture -->
    <video id="cameraFeed" playsinline autoplay muted></video>
    <canvas id="captureCanvas"></canvas>

    <button id="microphoneBtn" aria-label="Microphone"></button>
    
    <div id="textFallback">
      <p>Your browser may not support all features. Try typing your message:</p>
      <input type="text" id="textInput" placeholder="Type your message here">
      <button id="sendTextBtn">Send</button>
    </div>
    
    <div id="conversation"></div>
    <audio id="responseAudio" controls style="display:none;"></audio>

    <div style="text-align:center; margin-top:10px;">
      <label for="speedSelect" style="color:#fff; font-size:0.9rem; margin-right:5px;">Playback Speed:</label>
      <select id="speedSelect" style="padding:4px 8px; font-size:0.9rem; border-radius:4px; border:1px solid #ccc;">
        <option value="0.5">0.5√ó</option>
        <option value="0.75">0.75√ó</option>
        <option value="1.15" selected>1.15√ó</option>
        <option value="1.2">1.2√ó</option>
        <option value="2">2√ó</option>
      </select>
    </div>
    <div class="author">Developed by Surya Nallamothu ‚ù§Ô∏è‚Äçüî•</div>
    <div class="author">If any queries, message me :<a href="https://wa.me/9392567247?text=My%20Query%20%3A" target="_blank"> WhatsApp</a></div>
  </div>

  <script defer>
    (() => {
      'use strict';
      
      if (!window.fetch) {
        alert('Your browser does not support the Fetch API. Please update your browser.');
        return;
      }
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        alert('Your browser does not support camera access (getUserMedia API). Some features will be disabled.');
      }
      
      const languageSelect = document.getElementById('languageSelect');
      const microphoneBtn = document.getElementById('microphoneBtn');
      const textFallback   = document.getElementById('textFallback');
      const textInput      = document.getElementById('textInput');
      const sendTextBtn    = document.getElementById('sendTextBtn');
      const conversationDiv= document.getElementById('conversation');
      const responseAudio  = document.getElementById('responseAudio');
      const speedSelect    = document.getElementById('speedSelect');

      // Avatar and Camera elements
      const avatarVideo = document.getElementById('avatarVideo');
      const cameraFeed = document.getElementById('cameraFeed');
      const captureCanvas = document.getElementById('captureCanvas');
      const captureCtx = captureCanvas.getContext('2d');
      let cameraStream = null;
      let latestFrameDataURL = null;
      let captureInterval = null;

      // Define paths to your video assets
      const videoAssets = {
        idle: './videos/idle.mp4', // Replace with your actual video path
        listening_active: './videos/listening_active.mp4', // Replace with your actual video path
        speaking: './videos/speaking.mp4', // Replace with your actual video path
        thinking: './videos/thinking.mp4', // Replace with your actual video path
      };

      let conversationHistory = "";
      const isMobile = /Mobi|Android/i.test(navigator.userAgent);
      let alwaysOn = !isMobile, isRecording = false, isResponsePlaying = false, querySent = false;
      
      const languageMap = { /* Your existing languageMap... */
        "en": { name: "English", locale: "en-US" }, "hi": { name: "Hindi", locale: "hi-IN" }, "te": { name: "Telugu", locale: "te-IN" }, // Add more
        // ... (keep your full languageMap here)
         "af": { name: "Afrikaans", locale: "af-ZA" }, "sq": { name: "Albanian", locale: "sq-AL" }, "ar": { name: "Arabic", locale: "ar-SA" }, "hy": { name: "Armenian", locale: "hy-AM" }, "bn": { name: "Bengali", locale: "bn-BD" }, "bs": { name: "Bosnian", locale: "bs-BA" }, "ca": { name: "Catalan", locale: "ca-ES" }, "cs": { name: "Czech", locale: "cs-CZ" }, "da": { name: "Danish", locale: "da-DK" }, "de": { name: "German", locale: "de-DE" }, "el": { name: "Greek", locale: "el-GR" }, "eo": { name: "Esperanto", locale: "eo" }, "es": { name: "Spanish", locale: "es-ES" }, "et": { name: "Estonian", locale: "et-EE" }, "fi": { name: "Finnish", locale: "fi-FI" }, "fr": { name: "French", locale: "fr-FR" }, "gu": { name: "Gujarati", locale: "gu-IN" }, "hr": { name: "Croatian", locale: "hr-HR" }, "hu": { name: "Hungarian", locale: "hu-HU" }, "is": { name: "Icelandic", locale: "is-IS" }, "id": { name: "Indonesian", locale: "id-ID" }, "it": { name: "Italian", locale: "it-IT" }, "ja": { name: "Japanese", locale: "ja-JP" }, "jw": { name: "Javanese", locale: "jv-ID" }, "kn": { name: "Kannada", locale: "kn-IN" }, "km": { name: "Khmer", locale: "km-KH" }, "ko": { name: "Korean", locale: "ko-KR" }, "la": { name: "Latin", locale: "la" }, "lv": { name: "Latvian", locale: "lv-LV" }, "mk": { name: "Macedonian", locale: "mk-MK" }, "ml": { name: "Malayalam", locale: "ml-IN" }, "mr": { name: "Marathi", locale: "mr-IN" }, "my": { name: "Burmese", locale: "my-MM" }, "ne": { name: "Nepali", locale: "ne-NP" }, "no": { name: "Norwegian", locale: "no-NO" }, "pl": { name: "Polish", locale: "pl-PL" }, "pt": { name: "Portuguese", locale: "pt-BR" }, "pa": { name: "Punjabi", locale: "pa-IN" }, "ro": { name: "Romanian", locale: "ro-RO" }, "ru": { name: "Russian", locale: "ru-RU" }, "sr": { name: "Serbian", locale: "sr-RS" }, "si": { name: "Sinhala", locale: "si-LK" }, "sk": { name: "Slovak", locale: "sk-SK" }, "su": { name: "Sundanese", locale: "su-ID" }, "sw": { name: "Swahili", locale: "sw-KE" }, "sv": { name: "Swedish", locale: "sv-SE" }, "ta": { name: "Tamil", locale: "ta-IN" }, "th": { name: "Thai", locale: "th-TH" }, "tr": { name: "Turkish", locale: "tr-TR" }, "uk": { name: "Ukrainian", locale: "uk-UA" }, "ur": { name: "Urdu", locale: "ur-PK" }, "vi": { name: "Vietnamese", locale: "vi-VN" }, "cy": { name: "Welsh", locale: "cy-GB" }
      };
      
      Object.keys(languageMap).forEach(code => {
        const option = document.createElement("option");
        option.value = code;
        option.textContent = `${languageMap[code].name} (${languageMap[code].locale})`;
        languageSelect.appendChild(option);
      });
      languageSelect.value = "en"; // Default to English

      speedSelect.addEventListener('change', () => {
        responseAudio.playbackRate = parseFloat(speedSelect.value);
      });

      // --- Avatar State Management ---
      function setAvatarState(state) {
        const videoSrc = videoAssets[state];
        if (avatarVideo.currentSrc.endsWith(videoSrc)) return; // Already playing this video
        
        avatarVideo.src = videoSrc;
        avatarVideo.play().catch(e => console.warn("Avatar video play interrupted or failed:", e));

        // Start/stop camera frame capture based on state (optional, for sending visual context)
        if (state === 'listening_active' || state === 'idle') {
          startFrameCapture(); // Capture frames when listening or idle
        } else {
          stopFrameCapture(); // Stop capturing when speaking or thinking (to save resources)
        }
      }

      // --- Camera and Frame Capture ---
      async function setupCamera() {
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
          console.warn("getUserMedia not supported. Visual input disabled.");
          textFallback.style.display = 'block'; // Show text fallback if camera essential
          return;
        }
        try {
          cameraStream = await navigator.mediaDevices.getUserMedia({ video: true });
          cameraFeed.srcObject = cameraStream;
          // Set canvas dimensions once video metadata is loaded
          cameraFeed.onloadedmetadata = () => {
              captureCanvas.width = cameraFeed.videoWidth / 4; // Smaller canvas for less data
              captureCanvas.height = cameraFeed.videoHeight / 4;
          };
          setAvatarState('idle'); // Initial state
        } catch (err) {
          console.error("Error accessing camera:", err);
          appendMessage("Bujji: I can't access your camera. Visual features will be off.");
          textFallback.style.display = 'block'; // Show text fallback
        }
      }

      function captureFrame() {
        if (cameraStream && cameraFeed.readyState >= cameraFeed.HAVE_CURRENT_DATA) {
          captureCtx.drawImage(cameraFeed, 0, 0, captureCanvas.width, captureCanvas.height);
          latestFrameDataURL = captureCanvas.toDataURL('image/jpeg', 0.5); // JPEG, 50% quality
        }
      }

      function startFrameCapture() {
        if (!cameraStream) return;
        if (!captureInterval) {
          captureFrame(); // Capture one immediately
          captureInterval = setInterval(captureFrame, 2000); // Capture every 2 seconds
        }
      }

      function stopFrameCapture() {
        if (captureInterval) {
          clearInterval(captureInterval);
          captureInterval = null;
          latestFrameDataURL = null; // Clear last frame when not actively capturing
        }
      }
      
      setupCamera(); // Initialize camera on load

      // --- Speech Recognition ---
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      const hasSpeechRecognition = !!SpeechRecognition;
      let recognition;

      if (hasSpeechRecognition) {
        recognition = new SpeechRecognition();
        recognition.continuous = false; // Process after pause
        recognition.interimResults = true; // Get interim for responsiveness
        recognition.onstart = () => {
          isRecording = true;
          microphoneBtn.classList.add('active');
          setAvatarState('listening_active');
          // INTERUPTION: If Bujji is speaking, stop it.
          if (isResponsePlaying && !responseAudio.paused) {
            responseAudio.pause(); // This will trigger onended/onpause
          }
        };
        recognition.onresult = event => {
          let transcript = "";
          for (let i = event.resultIndex; i < event.results.length; i++) {
            if (event.results[i].isFinal) {
              transcript = event.results[i][0].transcript.trim();
            } else {
              // Interim results can be displayed if needed
              // console.log("Interim: ", event.results[i][0].transcript);
            }
          }
          if (transcript && !querySent) { // Ensure querySent check
            recognition.stop(); // Stop recognition once final result is obtained
            querySent = true;
            appendMessage("Me: " + transcript);
            sendQuery(transcript);
          }
        };
        recognition.onerror = event => {
          console.error("Speech recognition error:", event.error);
          if (event.error === 'no-speech' || event.error === 'audio-capture') {
             appendMessage("Bujji: I didn't hear anything or there's an issue with the mic.");
          } else if (event.error === 'not-allowed') {
             appendMessage("Bujji: I don't have permission to use the microphone.");
          } else {
             appendMessage("Bujji: Oops, speech recognition had a hiccup.");
          }
          isRecording = false;
          microphoneBtn.classList.remove('active');
          setAvatarState('idle');
        };
        recognition.onend = () => {
          isRecording = false;
          microphoneBtn.classList.remove('active');
          if (!querySent) { // If no query was sent (e.g., stopped manually or timeout)
             setAvatarState('idle');
          }
          if (alwaysOn && !querySent && !isResponsePlaying && !isMobile) {
            // Delay before restarting always-on to prevent immediate re-trigger
            setTimeout(() => { if (alwaysOn && !isRecording && !isResponsePlaying) recognition.start(); }, 500);
          }
        };
      } else {
        textFallback.style.display = 'block';
        microphoneBtn.style.display = 'none'; // Hide mic button if no STT
        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
           // Recorder.js fallback (simplified, consider if really needed with text fallback)
            console.log("Using Recorder.js fallback for audio input.");
        }
      }

      function startRecognition() {
        if (querySent || isRecording || isResponsePlaying) return; // Don't start if busy
        
        if (hasSpeechRecognition) {
          recognition.lang = languageMap[languageSelect.value]?.locale || languageSelect.value;
          recognition.start();
        } else if (window.recorder) { // Recorder.js fallback
          isRecording = true;
          microphoneBtn.classList.add('active');
          setAvatarState('listening_active');
          if (isResponsePlaying && !responseAudio.paused) {
            responseAudio.pause();
          }
          window.recorder.record();
        }
      }

      function stopRecognition() {
        if (hasSpeechRecognition && isRecording) {
          recognition.stop();
        } else if (window.recorder && isRecording) { // Recorder.js fallback
            isRecording = false;
            microphoneBtn.classList.remove('active');
            setAvatarState('idle');
            window.recorder.stop();
            window.recorder.exportWAV(function(blob) {
                const formData = new FormData();
                formData.append('audio_data', blob, 'recording.wav');
                querySent = true; // Assume query will be sent
                fetch('/speech-to-text', { method: 'POST', body: formData })
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        appendMessage("Bujji: Error: " + data.error);
                        querySent = false;
                        setAvatarState('idle');
                    } else {
                        appendMessage("Me: " + data.transcript);
                        sendQuery(data.transcript); // sendQuery will set thinking avatar
                    }
                    window.recorder.clear();
                })
                .catch(err => {
                    console.error('Error in speech-to-text fallback:', err);
                    appendMessage("Bujji: Error processing your speech.");
                    querySent = false;
                    setAvatarState('idle');
                    window.recorder.clear();
                });
            });
        }
      }


      const sendQuery = async (question) => {
        conversationHistory += "Me: " + question + "\n";
        setAvatarState('thinking');
        document.body.classList.remove('speaking-active'); // Remove speaking gradient if it was on

        const payload = {
            history: conversationHistory,
            imageData: latestFrameDataURL // Send current camera frame
        };
        latestFrameDataURL = null; // Clear after sending

        try {
          const response = await fetch('/query', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(payload)
          });
          const data = await response.json();
          if (data.error) {
            appendMessage("Bujji: Error - " + data.error);
            querySent = false;
            setAvatarState('idle');
            return;
          }

          if (data.response.trim().toUpperCase().startsWith("OPEN:")) {
            const url = data.response.substring(5).trim();
            appendMessage("Bujji: Opening " + url);
            setAvatarState('speaking'); // Briefly show speaking for "Opening..."
            window.open(url, '_blank');
            // After a short delay, return to idle or listening
            setTimeout(() => {
                querySent = false;
                setAvatarState('idle');
                if (alwaysOn && !isMobile) startRecognition();
            }, 1500);
          } else {
            appendMessage("Bujji: " + data.response);
            conversationHistory += "Bujji: " + data.response + "\n";
            if (data.audio) {
              playTTS("data:audio/mpeg;base64," + data.audio);
            } else {
              querySent = false;
              setAvatarState('idle');
              if (alwaysOn && !isMobile) startRecognition();
            }
          }
        } catch (err) {
          console.error("Error in query:", err);
          appendMessage("Bujji: I'm having trouble connecting. Please try again.");
          querySent = false;
          setAvatarState('idle');
          if (alwaysOn && !isMobile) startRecognition();
        }
      };

      const playTTS = (audioURL) => {
        responseAudio.src = audioURL;
        responseAudio.playbackRate = parseFloat(speedSelect.value);
        
        // Ensure AudioContext is resumed (for browsers that suspend it)
        if (responseAudio.played.length === 0) { // Or check AudioContext state if using visualizer
             // User interaction might be needed to start audio in some browsers.
        }

        responseAudio.play()
          .then(() => {
            isResponsePlaying = true;
            document.body.classList.add('speaking-active');
            setAvatarState('speaking');
          })
          .catch(error => {
            console.error("Audio play failed:", error);
            appendMessage("Bujji: I couldn't play the audio response.");
            isResponsePlaying = false; // Reset flag
            querySent = false;
            document.body.classList.remove('speaking-active');
            setAvatarState('idle');
            if (alwaysOn && !isMobile) startRecognition();
          });
      };

      responseAudio.onended = () => {
        isResponsePlaying = false;
        document.body.classList.remove('speaking-active');
        querySent = false;
        setAvatarState('idle');
        if (alwaysOn && !isMobile && !isRecording) { // Check !isRecording
            startRecognition();
        }
      };
      // Also handle pause event for interruption
      responseAudio.onpause = () => {
        isResponsePlaying = false; // Important for interruption
        document.body.classList.remove('speaking-active');
        // Don't reset querySent here if pause was due to interruption
        if (!isRecording) { // If paused not due to user speaking
            setAvatarState('idle');
            if (alwaysOn && !isMobile) startRecognition();
        }
      };


      microphoneBtn.addEventListener('click', () => {
        if (!isRecording) {
            startRecognition();
        } else {
            stopRecognition(); // This will handle stopping and processing if needed.
        }
      });
      
      // Toggle always-on for desktop (simplified)
      if (!isMobile) {
          // Could add a button or setting for this
          console.log("Desktop: Always-on listening enabled by default (if supported).");
      }


      sendTextBtn.addEventListener('click', () => {
        const text = textInput.value.trim();
        if (text) {
          if (isResponsePlaying && !responseAudio.paused) { // INTERRUPT if speaking
              responseAudio.pause();
          }
          querySent = true; // Set before sending
          appendMessage("Me: " + text);
          sendQuery(text);
          textInput.value = "";
        }
      });
      textInput.addEventListener('keypress', e => {
        if (e.key === 'Enter') sendTextBtn.click();
      });

      const appendMessage = message => {
        const p = document.createElement('p');
        p.textContent = message;
        conversationDiv.appendChild(p);
        conversationDiv.scrollTop = conversationDiv.scrollHeight;
      };

      // Set initial avatar state
      setAvatarState('idle'); 
      if (alwaysOn && !isMobile && hasSpeechRecognition) {
          // Start listening if always on, not mobile, and STT is supported
          // Delay slightly to ensure everything is initialized
          setTimeout(startRecognition, 1000);
      }


      // Fallback Recorder.js initialization (if you keep this for non-SpeechRecognition browsers)
      if (!hasSpeechRecognition && navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {
                const AudioContext = window.AudioContext || window.webkitAudioContext;
                if (AudioContext) {
                    const audioContext = new AudioContext();
                    const input = audioContext.createMediaStreamSource(stream);
                    window.recorder = new Recorder(input, { numChannels: 1 });
                    microphoneBtn.style.display = 'block'; // Show mic button if recorder is ready
                    textFallback.style.display = 'none';
                } else {
                    textFallback.style.display = 'block';
                    microphoneBtn.style.display = 'none';
                }
            })
            .catch(err => {
                console.error('Audio capture error for fallback:', err);
                textFallback.style.display = 'block';
                microphoneBtn.style.display = 'none';
            });
      } else if (!hasSpeechRecognition) {
          textFallback.style.display = 'block';
          microphoneBtn.style.display = 'none';
      }


    })();
  </script>
</body>
</html>